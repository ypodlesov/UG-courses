
# Сортировки и поиск. Часть 1.

## Пирамидальная сортировка

### Пирамиды

**Бинарная пирамида** - объект-массив, который можно рассматривать, как почти
полное бинарное дерево. Каждый узел дерева соответствует элементу массива. 

**Почти полное** бинарное дерево - бинарное дерево заполненное на всех
уровнях, кроме возможно последноего. 

Массив $A$ - объект с двумя атрибутами: 
1. `A.length` - сколько элементов в массиве.
2. `A.heap-size` - сколько из них **корректные** элементы пирамиды.

Пирамиды бывают **невозрастающие** и **неубывающие**. Ниже мы будем рассматривать
невозрастающие пирамиды. Все рассуждения для невозрастающих пирамид очевидным
образом переносятся на случай неубывающих.

**Свойство невозрастающей пирамиды** - для любого элемента пирамиды, кроме
корневого узла верно: `A[Parent(i)] >= A[i]`.

**Корректный элемент** невозрастающей пирамиды - элемент, удовлетворяющий её
свойству. 

**Корневой узел** пирамиды - `A[1]`.

Каждый узел имеет не более двух **дочерних узлов**. Все узлы кроме корневого 
имеют ровно один **родительский узел**. Вычислить их можно следующим образом:

```
Parent(i) = i / 2
Left(i) = 2 * i
Right(i) = 2 * i + 1
```

Такие языки как **C++** поддерживают битовые операции. Так что коды выше можно
переписать в такой более быстрый:

```cpp
int Parent(i) {
    return i >> 1;
}
int Left(i) {
    return i << 1;
}
int Right(i) {
    return (i << 1) | 1;
}
```

**Высота узла** пирамиды - число рёбер в самом длинном нисходящем простом пути от этого
узла к какому-то из листьев.

Так как пирамида из $n$ элементов строится по принципу полного бинарного дерева,
то её высота пропорциональна $\lg(n)$. Поэтому большинство операций над
пирамидой имеют временную сложность $O(\lg n)$

ВВедём четыре процедуры:

1. `Max-Heapify` - служит для поддержки свойства пирамиды, выполняется за $O(\lg
   n)$.
2. `Build-Max-Heap` - предназначена для создания пирамиды из неупорядоченного
   входного массива, выполняется за $O(n)$.
3. `Heapsort` - сортирует массив, выполняется за $O(n\lg n)$.
4. `Max-Heap-Insert`, `Heap-Extract-Max`, `Heap-Increase-Key` и `Heap-Maximum` -
   позволя/т использовать пирамиду для реализации очереди с приоритетами,
   выполняются за время $O(\lg n)$. 

### Поддержка свойств пирамиды

Начнём с процедуры `Max-Heapify(A, i)`. Входные данные - массив `A` и индекс `i` в этом массиве.

При вызове этой процедуры предполагается, что поддеревья с корнями в `Left(i)` 
и `Right(i)` представляют собой корректные невозрастающие пирамиды. И нужно
поставить элемент `A[i]` на место так, чтобы пирамида с корнем в вершине `i`
была корректной.

```
Max-Heapify(A, i)
    l = Left(i)
    r = Right(i)
    largest = i
    if (l <= A.heap-size and A[l] > A[largest])
        largest = l
    if (r <= A.heap-size and A[r] > A[largest])
        largest = r
    if (largest != i)
        swap(A[largest], A[i])
        Max-Heapify(A, largest)
```

Очевидно на каждом шаге кроме последнего мы перемещаемся в узел, который имеет
высоту на один меньше, пожтому время работы данной процедуры $O(\lg n)$. 

### Построение пирамиды

Чтобы построить невозрастающую пирамиду, можно просто воспользоваться процедурой
`Max-Heapify` в восходящем направлении. Начинаем с листьев дерева 
$A[n/2 + 1, \ldots , n$.

```
Build-Max-Heap(A) 
    A.heap-size = A.length
    for i = A.length / 2 ... 1
        Max-Heapify(A, i)
```

Докажем корректность этой процедуры воспользовавшись следующим инвариантом цикла: 

***В начале каждой итерации цикла for каждый узел $i+1, \ldots , n$ является
корнем невозрастающей пирамиды***

**Инициализация.** Перед первой итерацией $i = n/2$, все вершины с индексами
$i+1, \ldots , n$ являются листьями. Поэтому каждый из них является корнем
тривиальной невозрастающей пирамиды.

**Сохранение.** В соответсвии с инвариантом, все узлы с индексами $> i$ являются
корнями невозрастающих пирамид. Это условие для вызова процедуры `Max-Heapify`.
Следовательно после уменьшения $i$ на 1 инвариант будет выполнен. 

**Завершение.** По завершении цикла $i = 0$. Следовательно Корнем является узел
с индексом 1.

Таким образом мы доказали корректность процедуры `Build-Max-Heap`. 

Получим верхнюю оценку для времени работы данной процедуры. Простая верхняя
оценка - $O(n\lg n)$. Она верная, но не точная.

Попробуем получить болеее точную:

$$
\sum\limits_{h=0}^{\lfloor{\lg n}\rfloor} \lceil\frac{n}{2^{h+1}}\rceil O(h) 
= O\left( n \sum\limits_{h = 0}^{\lfloor \lg n \rfloor} \frac{h}{2^h} \right) =
O(n)
$$

Следовательно построить невозрастающую пирамиду из неупорядоченного массива
можно за линейное время.

### Алгоритм пирамидальной сортировки

Алгоритм пирамидальной сортироки очень прост. Сначала мы строим невозрастающую
пирамиду на входном массиве. После этого мы $n-1$ раз берём элемент с вершины
пирамиды и меняем его с последним элемнтом пирамиды. А для пирамиды вызываем 
`Max-Heapify(A, 1)`. 

```
Heapsort(A)
    Build-Max-Heap(A)
    for i = A.length ... 2
        swap(A[1], A[i])
        A.heap-size = A.heap-size - 1
        Max-Heapify(A, 1)
```

Время работы `Heapsort` составляет $O(n\lg n)$, так как `Build-Max-Heap` -
требует $O(n)$ времени, а каждый из $n - 1$ вызова `Max-Heapify` - $O(\lg n)$
времени.

### Очереди с приоритетами

Пирамида, которую мы рассмотрели ранее часто применяется как **очередь с 
приоритетами**. Как и пирамида очередь с приоритетами может быть невозрастающей
или неубывающей. Мы рассмотрим реализацию невозрастающей.

**Очередь с приориетами** - структура данных, предназначенная для обслуживания
множества $S$, с каждым элементом которого связано определенное значение,
называемое **ключом**. 

Невозрастающая очередь с приоритетами поддерживает следующие операции:

1. `Insert(S, x)` - вставляет элемент $x$ в множество $S$. То есть $S = S \cup x$.
2. `Maximum(S)` - возвращает элемент множества $S$ с наибольшим ключом. 
3. `Extract-Max(S)` - удаляет и возвращает элемент множества $S$ с наибольшим
   ключом.
4. `Increase-Key(S, x, k)` - увеличивает значение ключа элемента $x$ до нового
   значения $k$, которое предполагается не меньшим значения текущего ключа
   элемента $x$. 

Приведём реализацию каждой из процедур:

```
Heap-Maximum(A)
    return A[1]
```

Время работы `Heap-Maximum` - $O(1)$.

```
Heap-Extract-Max(A)
    if A.heap-size < 1
        error "Очередь пуста"
    max = A[1]
    A[1] = A[A.heap-size]
    A.heap-size = A.heap-size - 1
    Max-Heapify(A, 1)
    return max
```

Время работы `Heap-Extract-Max` - $O(\lg n)$

```
Heap-Increase-Key(A, i, key)
    if key < A[i]
        error "Новый ключ меньше текущего"
    A[i] = key
    while i > 1 and A[Parent(i)] < A[i]
        swap(A[i], A[Parent(i)])
        i = Parent(i)
```

Время работы `Heap-Increase-Key` - $O(\lg n)$

```
Max-Heap-Insert(A, key)
    A.heap-size = A.heap-size + 1
    A[A.heap-size] = -INF
    Heap-Increase-Key(A, A.heap-size, key)
```

Время работы `Max-Heap-Insert` - $O(\lg n)$

## Быстрая сортировка

Адгоритм **быстрой сортировки** использует парадигму "разделяй и властвуй". Как
все алгоритмы, использующие данную парадигму, он включает три этапа:
*разделение*, *властвование* и *комбинирование*.

Приведём общую схему быстрой сортировки подмассива $A[p \ldots r]$:

- **Разделение:** Массив $A[p \ldots r]$ разбивается на два (возможно пустых)
    подмассива $A[p \ldots q-1]$ и $A[q+1 \ldots r]$ таких, что каждый элемент
    $A[p \ldots q-1]$ не больше $A[q]$, а каждый элемент $A[q+1 \ldots r]$ 
    не меньше $A[q]$. Индекс $q$ вычисляется в процедуре разбиения `Partition`.
- **Властвование:** Подмассивы $A[p \ldots q-1]$ и $A[q+1 \ldots r]$ сортируются
    при помощи рекурсивного вызова процедуры быстрой сортировки.
- **Комбинирование:** После сортировки $A[p \ldots q-1]$ и $A[q+1 \ldots r]$
    весь подмассив $A[p \ldots r]$ оказывается отсортирован.

Быстрая сортировка реализуется следующей процедурой:

```
Quicksort(A, p, r)
    if p < r
        q = Partition(A, p, r)
        Quicksort(A, p, q - 1)
        Quicksort(A, q + 1, r)
```

### Разбиение массива

Ключевой частью алгоритма быстрой сортировки является процедура разбиения
`Partition`, изменяющая порядок элементов подмассива $A[p \ldots r$ на месте (то
есть без привлечения дополнительной памяти).

```
Partition(A, p, r)
    x = A[r]
    i = p - 1
    for j = p to r - 1
        if A[j] <= x
            i = i + 1
            swap(A[i], A[j])
    swap(A[i+1], A[r])
    return i + 1
```

Эта процедура всегда выбирает $A[r]$ как опорный. Разбиение подмассива $A[p
\ldots r]$ будет выполняться относительно этого элемента.

Сформулируем следующий инвариант цикла `for` для процедуры `Partition`:

*В начале каждой итерации цикла* `for` *для любого индекса* $k$ *массива
справедливо:*

1. *если* $p \le k \le i$, *то* $A[k] \le x$;
2. *если* $i + 1 \le k \le j - 1$ *то* $A[k] > x$;
3. *если* $k = r$ *то* $A[k] = x$;

Несложно доказывается, что данный инвариант удовлетворяет трём свойствам:
**инициализации**, **сохранению** и **завершению**. Следовательно, алгоритм
быстрой сортировки является корректным.

Временная сложность быстрой сортироовки составляет $O(n^2)$ в худшем случае. Но
на практике она оказывается более эффективной чем сортировка слиянием или
пирамидальная сортировка. 

> Быстрая сортировка была разработана Тони Хоаром в 1960. 


































